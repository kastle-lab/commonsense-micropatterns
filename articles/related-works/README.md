# [ITERATIVE ZERO-SHOT LLM PROMPTING FOR KNOWLEDGE GRAPH CONSTRUCTION](https://arxiv.org/abs/2307.01128)
Salvatore Carta, Alessandro Giuliani, Leonardo Piano, Alessandro Sebastian Podda, Livio Pompianu, Sandro Gabriele Tiddia

The research continues previous works that have leveraged LLMs and transformers to automate the construction of KGs.  While previous research has a reliance on some form of supervised models, this research leverages an existing pre-trained LLM without providing further knowledge, utilizing zero-shot prompting. The research pre-trained GPT-3.5 with tourism information about Sardinia and the resulting Ontology and KG scored considerably high in accuracy-based metrics. 

# [Towards Ontology Construction with Language Models](https://arxiv.org/pdf/2309.09898)
Maurice Funk, Simon Hosemann, Jean Christoph Jung, Carsten Lutz

The authors pose Ontology Construction as a more challenging task for LLMs to accomplish due to the intricacies typically seen with software engineering and the process of design choice selection. The research focuses on leveraging LLMs to construct a concept hierarchy as a first step approach of designing a KG's schema. The authors generalize their formulated algorithm with a loop between five steps:
* Existence:  Check if concept C has subconcepts, constructing the class hierarchy
* Listing: Provide a list L of the subconcepts of C
* Description: Provide a description of each concept in list L
* Verification: Verify that all entries in List L is a subconcept of C
* Insertion:  Insert appropriately verified entries into the concept hierarchy H

# [Can Large Language Models Augment a Biomedical Ontology with missing Concepts and Relations?](https://arxiv.org/pdf/2311.06858)
Antonio Zaitoun, Tomer Sagi, Szymon Wilk, Mor Peleg

The short paper reports on the potential of utilizing general-purpose LLMs that have not been specifically trained with biomedical data to correctly represent missing concepts and relationships. Interestingly, the research found that the LLM found concepts and relationships that human experts regarded as valid and imporatant but was not originally in the original ontologies.

# [AutoKG: Efficient Automated Knowledge Graph Generation for Language Models](https://arxiv.org/pdf/2311.14740)
Bohan Chen, Andrea L. Bertozzi

The authors introduce AutoKG as a method for automating KG generation from an external knowledge base.

# [From human experts to machines: An LLM supported approach to ontology and knowledge graph construction](https://arxiv.org/pdf/2403.08345)
Vamsi Krishna Kommineni, Birgitta KÃ¶nig-Ries, Sheeba Samuel

The research employs LLMs to semi-automate the process in KG construction. LLMs are used from the start, such as generating the use case documentation in the form of competency questions, to the end result of KG construction itself. The research has promising results for supplementing humans for LLMs throughout the KG construction pipeline; however, domain experts are still a valuable resource for data collection.

# [Navigating Ontology Development with Large Language Models](https://link.springer.com/chapter/10.1007/978-3-031-60626-7_8)
Mohammad Javad Saeedizade & Eva Blomqvist 

The study compares student solutions of ontologies with those generated by LLMs. The research heavily focuses on the prompting techniques and the generated OWL files as a result of the LLMs.

Perhaps more relevant due to the focus on prompting techniques rather than the LLMs generation itself...

# [Automated Construction of Theme-specific Knowledge Graphs](https://arxiv.org/pdf/2404.19146v1)
Linyi Ding, Sizhe Zhou, Jinfeng Xiao, Jiawei Han

The research introduces an unsupervised framework in order to generate ThemeKGs, or knowledge graphs constructed from a theme-specific corpus. The authors report that directly prompting LLMs to generate ThemeKGs can lead to inaccuracies in entity and relationship representation; however, their introduced framework leverages the power of LLMs alongside the knowledge of Wikipedia to result in higher performance accuracies.

# [LLMs for Knowledge Graph Construction and Reasoning: Recent Capabilities and Future Opportunities](https://arxiv.org/pdf/2305.13168)
Yuqi Zhu, Xiaohan Wang, Jing Chen, Shuofei Qiao, Yixin Ou, Yunzhi Yao, Shumin Deng, Huajun Chen, Ningyu Zhang

The research challenges current research attempts in leveraging LLMs for KG Construction and reasoning by introducing a novel dataset to benchmark LLMs with. The researchers also develop their own AutoKG, not to be confused with Chen and Bertozzi's AutoKG, to automatically generate KGs which also leverages multi-agent communication.